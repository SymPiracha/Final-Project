# **US Elections Analysis**

# Overview 

In this data analysis, we used Reddit’s API to pull posts from the subreddits r/politics and r/Conservative over four (4) consecutive days (11/23 - 11/26). After annotating and by analysing the dataset, we came up with 8 different topics to categorize the posts. Needless to say, deciding on the topics was less obvious than we anticipated as we didn’t want to be too broad while also wanting to be able to assign each post an appropriate topic. After a decent deal of discussion, our team came to a conclusion on the topics and we then calculated the TF-IDF scores (a formula to find uniquely commonly used words among a set of documents). Some topics were more prevalent than others, such as: election fraud, scandals involving President Trump, President-Elect Biden’s policies, and simply the results of this past election. Finally, the main takeaway after all this was that American citizens on both sides of the aisle are greatly concerned and/or intrigued with the fairness of this past election. Many posts from both r/politics and r/Conservative － even 20+ days after election day － discussed the possibilities and ramifications of a fraudulent election. 





## Data

The greatest deal of discussion amongst the team revolved around the collection of the data. We were asked to collect 1000 posts from each subreddit over a 3-day period and so we decided quite quickly that we would pull 333 posts per subreddit, per day for the first two (2) days, and 334 posts per subreddit on the 4th day; this seemed like the fairest and most unbiased way to proceed. However, in our first meeting, we realized that pulling the posts by “New” may not accurately reflect the subreddit’s most characterizing topics that day, but rather simply the most recent posts at the time we made the API call. As a result, we narrowed our decision down to “Hot” and “Top”. After some further research and even more discussion, we settled on using the “Top” API to get our posts as we concluded that having the greatest amount of “upvotes” (similar to a “like” on other social media platforms) implied a general consensus on a post’s topic among the subreddit’s members. Furthermore, ranking posts by “Hot” could have led to certain posts that are “pinned” by moderators to be included in the dataset; these posts tend to not be opinionated but rather informative (typically of an open discussion taking place in the comments of said post). Our next hurdle occurred when trying to pull 333 posts from r/Conservative on the first day, and only 269 were being pulled. Our initial thought is that this specific day is an anomaly since we were aware from past assignments that r/politics had 500+ posts per day, and we assumed r/Conservative would have similar numbers if we tried again the next day. Unfortunately, this is not the case and after confirming our next idea with Professor Ruths, we decided to pull 250 posts per subreddit, per day over a four (4) day period to hit 1000 posts per subreddit. Four days later, our initial dataset was complete and we moved to the next step- filtering posts for ones that mention either Trump or Biden. When writing this Python script, we made the decision to filter case-insensitive and bordered or non-bordered by special characters such as numbers, punctuation, unicode characters, and any other non-English characters. After running the filtering script, we were left with 297 posts from r/Conservative, and 642 posts from r/politics. While annotating these datasets, we came to realize that there were some posts with identical titles. As a result, we double checked that each of the posts with identical titles had different “post names” which ensured they were in fact different posts. We made the decision to keep these in our datasets since we did not feel that it misrepresented the content of the subreddits; we felt it only further contributed to the strength of the sentiment in regards to the respective type of post.

## Methods

We decided that the most efficient way to gather our dataset would be to make ‘GET’ requests to the reddit API. By changing the parameters of our request url, we were easily able to sort the posts we wanted by ‘Top’. Another parameter we could tweak was ‘limit’ which indicated how many posts we wanted to get per API request. As the reddit API limits users to fetch only 100 posts per request, we used the ‘after’ key from each request to filter values of the previous request to determine the next set of items. This process of getting the next set of 100 unique posts is known as API Pagination.
After collecting all of our posts, over a 4 day period, we merged all of the relevant files for each subreddit into one file for r/politics and r/Conservative. To make our data more readable we removed unnecessary columns, keeping only the unique name value for each post as well as the title. To aid with our annotation process, we included another ‘Coding’ column to indicate which category the title of the post belonged to. A ‘Date Collected’ column was included to showcase which date each post was from.
After merging all of our posts, we removed posts which did not include mention of either Trump or Biden. This was done by first converting the title of each post to lowercase and then by replacing any character which was not a lower case alphabet by a space (using Regex). The title was then checked to see if it contained the string “trump” or “biden”; if it did not, it was removed from the dataset.
The next step of the process was to compute 10 words in each annotated category with the highest tf-idf scores. This was done individually for both r/politics and r/Conservative. To calculate the tf-idf scores we first wrote a script to compute the word count for each word per annotation category. This script returned a nested dictionary which contained our annotation category as the ‘key’. The value of this ‘key’ was another dictionary which indicated as a key-value pair each word along the number of times it appeared in that specific category. In order to avoid storing too many irrelevant words, we removed those words which did not appear at least five times. Each word was treated as case insensitive, punctuation was replaced with a space and only words containing alpha characters were kept. All other words were ignored. After this was done we calculated the Term-Frequency by referring to our dictionary to check the number of times the word was mentioned for a specific annotation category. Inverse-Document-Frequency was calculated by taking the log of the number of annotation categories over the number of annotations in which the word is mentioned. The two results from TF and IDF were multiplied to obtain the TF-IDF value for each word. These values were then sorted in descending order and the top ten TF-IDF values for each category were returned.  

## Results

In order to find the categories for the annotation of our posts we conducted an open coding. For this process we took a sample of 200 posts from our collection of posts that mentioned “Trump” or “Biden”. In order to balance this sample we took 100 posts from r/Conservative and 100 from r/politics with 25 coming from each of the 4 days we collected posts on. With this sample we iterated over the posts 3 times. The first iteration was to get a sense of what the post titles were like and identify clear (albeit broad) categories. The second iteration helped make more concrete, specific categories and the third was used to fill in any gaps. After the open-coding we met as a group to discuss the overlap of some categories and decide which ones felt more appropriate to include and which ones we were comfortable dropping. After that whole process we decided on the eight following categories: “Trump Scandal”, “Biden Scandal”, “Trump Policy”, “Biden Policy”, “Transition”, “Election Fraud”, “Election Results”  and “Opinion”. We defined “Trump/Biden Scandal” as posts that talked directly about Trump or Biden scandals or controversies that were directly related to Trump, Biden, the Republicans, the Democrats or supporters of either party. (i.e Trump’s potential to be prosecuted after leaving, the Hunter Biden Scandal, corruption within the Republican Party, etc.) “Trump/Biden Policy” was defined as posts that talked directly about policy moves by either Trump or Biden, policy moves they were planning on making, or policy moves other politicians were encouraging them to make. (I.e “politician A wants Biden to enact a new policy to fix US-Canada relations”, “Trump Plans to enact policy B before he leaves office”, etc.) We chose to divide the policy and scandal into separate codings for both Trump and Biden just to see how the more liberal r/politics would talk about Biden vs Trump and vice-versa for r/Conservative. Next, “Election Fraud” was about posts that discussed direct claims (or the denunciation of claims) of election fraud, actions taken based on those claims and the results of those actions. (i.e “Judge throws out lawsuit by the Trump Administration in Georgia”). “Election Results” was reserved for posts that talked directly about vote counts reported, posts that Biden or Trump won a state, or posts that involved polling certain groups on who they voted for (i.e “90% of MIT students voted for Biden”). We chose to separate “Election Fraud” and “Election Results” as two separate categories because we figured that, based off the 200 post sample in the open coding, posts that would fall into the “Election Results” category would be more objective in nature as they mostly would just report the results as facts while the “Election Fraud” topics tended to have more editorialized titles. (For example, posts on r/politics tended to suggest that Trump’s legal actions were “an attempted coup” while r/Conservative posts would suggest the legal actions were justified and necessary to prevent Democrats from “stealing the election”).  “Transition” was used for posts that talked about the Biden Transition of power and included talks of politicians recognizing Biden’s victory or Trump refusing to concede. Lastly, “Opinion” was used to flag posts that were about public or politician opinions that did not fit into any of the other categories.


Above are tables showing results for the topics that we defined during our open coding. The “other” category is for posts that did not mention Trump or Biden and thus were not included in the data annotation process. For each topic we have included the amount of times it appeared as both a raw number and percentage, the percentage of non-other codings it made up (added to give a better perspective on which topics were discussed in each subreddit since there were almost twice as many “other” posts in r/Conservative than in r/politics), as well as the five words (case insensitive) that had the top TF-IDF scores. Note that since TF-IDF was calculated only on words that appeared at least five times for the topic, some topics with lower engagement (such as “Election Results” in r/Conservative) may have less than five top words.

## Discussion

Something interesting we noticed in our data was the “opinion” topic was the second most prevalent topic (13.51%) in r/Conservative, yet it was the second least prevalent topic in r/politics (8.21%) while “election results” was the second most prevalent topic in r/politics (18.58%) and the second least prevalent topic in r/Conservative. This was interesting as, based off the way we defined the topics, “opinion” seemed to be the topic that would be associated with post titles that were more subjective in nature (i.e op-eds) while “election results” was a topic that would be given to post titles that were more objective in nature (i.e just reporting facts on the election results). The rankings of these two topics in r/Conservative and r/politics seems to suggest that r/Conservative has somewhat of a preference for more editorialized or less factual content while r/politics seems to have a preference for more content that is more grounded by facts. One can argue that Trump’s affinity for calling out “fake news” may play a role in this phenomena.
As part of our discussion we thought it would be important to also address possible bias in our project which should be taken into consideration when interpreting the results. Firstly, by collecting our posts from reddit we introduced some bias since, according to a study by the Pew Research Centre, reddit users are disproportionately (compared to US adults) young, male and liberal. The effects of this were first observed during the data collection phase of our project where we needed to collect posts over four days (rather than three) since there were less than 333 posts per day on the r/Conservative subreddit. This also meant that the “top” posts of r/Conservative were likely almost identical to the “new” posts while the “top” posts of r/politics would likely be distinct from the “new” posts. Upon further research, we found that r/politics has more than 10 times as many subscribers (6,977,201) than r/Conservative (576,680). This could suggest that r/Conservative is less representative of conservatives than r/politics is of liberals. Also, since reddit users are typically younger and male that would mean that the posts on these subreddits are likely over-representing that demographic while under-representing women and older people who tend to have different political beliefs than young men. This difference in political views was shown in the 2020 presidential election where young men were more likely to vote democrat than older men but less likely to vote democrat than young women.  
In addition to this, people who post on these subreddits are those who place importance on contributing to the political discussion.  It is likely that these individuals have stronger political views and politics is something they care deeply about. As a result their views and opinions may not be a good representation of how the general population feels about such issues.
Having said all of that, our analysis showed that even though there was substantial overlap between what was being discussed in both subreddits, there were certain topics that were prevalent in one over the other. 
Policy, regardless of the fact which candidate it pertained to, was something that was widely discussed in both subreddits. Around a quarter of posts (24.14%) related to policy, indicating the great significance given to it by users. Another interesting category which was discussed in great detail surrounded scandals. Both subreddits had their fair share of posts discussing scandal for both candidates. The interesting thing we observed, however, was the r/Conserative subreddit focused more on pointing out Biden scandals and the r/politics subreddit focused more on Trump scandals. Findings such as these confirm our point and other research which indicates the liberal bias of r/politics. It can further be argued that the candidates, quite obviously, faced harsher criticisms from voters affiliated with their respective opposing party. Although this is expected, the high volume of criticism and strength of stances this year imply the sense of unity the candidates have instilled in their respective parties. 



## References

“Conservative.” Accessed December 6, 2020. https://www.reddit.com/r/Conservative/.
“Decoding the U.S. Election: What Data Reveal about Who Voted for Biden and Trump.” Accessed December 6, 2020. https://www.theglobeandmail.com/world/us-politics/article-decoding-the-us-election-what-data-reveal-about-who-voted-for-biden/.
“Politics.” Accessed December 6, 2020. https://www.reddit.com/r/politics/.
Pew Research Center’s Journalism Project. “Reddit News Users More Likely to Be Male, Young and Digital in Their News Preferences,” February 25, 2016. https://www.journalism.org/2016/02/25/reddit-news-users-more-likely-to-be-male-young-and-digital-in-their-news-preferences/.
